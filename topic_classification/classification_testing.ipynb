{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file is for classifies references into topics on a small portion of our dataset. To do this, we:\n",
    "\n",
    "* Used a 'BART' model to give each reference a confidence score for each topic.\n",
    "\n",
    "* Normalized the confidence scores using z-standarization\n",
    "\n",
    "* Coverted the confidence scores to binary if they scored in the top 65% for their topic\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First 120 rows with confidence scores:\n",
      "     book_filename author_of_book  birth_death  reference  \\\n",
      "0   books/1223.txt       Buchanan  1804 - 1870  aristotle   \n",
      "1   books/1223.txt       Buchanan  1804 - 1870  augustine   \n",
      "2   books/1223.txt       Buchanan  1804 - 1870   berkeley   \n",
      "3   books/1223.txt       Buchanan  1804 - 1870   berkeley   \n",
      "4   books/1223.txt       Buchanan  1804 - 1870   berkeley   \n",
      "..             ...            ...          ...        ...   \n",
      "60  books/1223.txt       Buchanan  1804 - 1870   holyoake   \n",
      "61  books/1223.txt       Buchanan  1804 - 1870   holyoake   \n",
      "62  books/1223.txt       Buchanan  1804 - 1870   holyoake   \n",
      "63  books/1223.txt       Buchanan  1804 - 1870   holyoake   \n",
      "64  books/1223.txt       Buchanan  1804 - 1870   holyoake   \n",
      "\n",
      "   full_author_referenced                                            context  \\\n",
      "0               Aristotle  l its laws and processes, its tribes and races...   \n",
      "1               Augustine  oth, 25 cts. philip doddridge. his life and la...   \n",
      "2                Berkeley  every man's reason, therefore, is really god; ...   \n",
      "3                Berkeley  nd \"object\" of thought are the same? or, wheth...   \n",
      "4                Berkeley  existence of unthinking things without any rel...   \n",
      "..                    ...                                                ...   \n",
      "60       Holyoake, Austin  son may thus rise from the contingent and vari...   \n",
      "61       Holyoake, Austin  show, either that it is _merely analogical_, a...   \n",
      "62       Holyoake, Austin  that there are marks of _design_ in nature, th...   \n",
      "63       Holyoake, Austin  r either that all these worlds must _now_ be i...   \n",
      "64       Holyoake, Austin  from the accident of our situation as sojourne...   \n",
      "\n",
      "    confidence_politics  confidence_ethics  confidence_epistemology  \\\n",
      "0                 0.045              0.136                    0.255   \n",
      "1                 0.069              0.148                    0.241   \n",
      "2                 0.036              0.119                    0.181   \n",
      "3                 0.057              0.103                    0.284   \n",
      "4                 0.101              0.110                    0.273   \n",
      "..                  ...                ...                      ...   \n",
      "60                0.050              0.134                    0.206   \n",
      "61                0.052              0.125                    0.231   \n",
      "62                0.067              0.122                    0.226   \n",
      "63                0.046              0.119                    0.221   \n",
      "64                0.061              0.119                    0.209   \n",
      "\n",
      "    confidence_logic  confidence_metaphysics  confidence_science  \\\n",
      "0              0.245                   0.205               0.076   \n",
      "1              0.129                   0.218               0.070   \n",
      "2              0.181                   0.331               0.049   \n",
      "3              0.190                   0.231               0.075   \n",
      "4              0.113                   0.215               0.100   \n",
      "..               ...                     ...                 ...   \n",
      "60             0.159                   0.260               0.083   \n",
      "61             0.284                   0.171               0.090   \n",
      "62             0.238                   0.194               0.099   \n",
      "63             0.271                   0.188               0.106   \n",
      "64             0.178                   0.245               0.100   \n",
      "\n",
      "    confidence_religion  \n",
      "0                 0.037  \n",
      "1                 0.125  \n",
      "2                 0.103  \n",
      "3                 0.060  \n",
      "4                 0.087  \n",
      "..                  ...  \n",
      "60                0.107  \n",
      "61                0.047  \n",
      "62                0.053  \n",
      "63                0.047  \n",
      "64                0.087  \n",
      "\n",
      "[65 rows x 13 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "\n",
    "categories = [\n",
    "    \"politics\", \"ethics\", \"epistemology\", \"logic\", \n",
    "    \"metaphysics\", \"science\", \"religion\",\n",
    "]\n",
    "\n",
    "df_test = pd.read_csv('references.csv', nrows=50)\n",
    "\n",
    "classifier = pipeline(\n",
    "    \"zero-shot-classification\",\n",
    "    model=\"cross-encoder/nli-distilroberta-base\",\n",
    "    device=-1\n",
    ")\n",
    "\n",
    "category_scores = {cat: [] for cat in categories}\n",
    "\n",
    "for text in df_test['context']:\n",
    "    try:\n",
    "        if not isinstance(text, str) or not text:\n",
    "            for cat in categories:\n",
    "                category_scores[cat].append(0.0)\n",
    "            continue\n",
    "\n",
    "        result = classifier(text, candidate_labels=categories)\n",
    "        \n",
    "        scores_dict = dict(zip(result['labels'], result['scores']))\n",
    "        \n",
    "        for cat in categories:\n",
    "            category_scores[cat].append(round(scores_dict.get(cat, 0.0), 3))\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing text: {str(e)}\")\n",
    "        for cat in categories:\n",
    "            category_scores[cat].append(0.0)\n",
    "\n",
    "for cat in categories:\n",
    "    df_test[f'confidence_{cat}'] = category_scores[cat]\n",
    "\n",
    "print(\"\\nFirst 50 rows with confidence scores:\")\n",
    "print(df_test)\n",
    "\n",
    "df_test.to_csv('test_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stats for confidence_politics:\n",
      "Original mean: 0.073\n",
      "Original std: 0.049\n",
      "Normalized mean: -0.048\n",
      "Normalized std: 0.746\n",
      "Normalized min: -1.131\n",
      "Normalized max: 3.000\n",
      "\n",
      "Stats for confidence_ethics:\n",
      "Original mean: 0.127\n",
      "Original std: 0.043\n",
      "Normalized mean: -0.033\n",
      "Normalized std: 0.853\n",
      "Normalized min: -2.231\n",
      "Normalized max: 3.000\n",
      "\n",
      "Stats for confidence_epistemology:\n",
      "Original mean: 0.210\n",
      "Original std: 0.057\n",
      "Normalized mean: -0.000\n",
      "Normalized std: 1.000\n",
      "Normalized min: -2.968\n",
      "Normalized max: 2.507\n",
      "\n",
      "Stats for confidence_logic:\n",
      "Original mean: 0.174\n",
      "Original std: 0.063\n",
      "Normalized mean: -0.022\n",
      "Normalized std: 0.911\n",
      "Normalized min: -2.065\n",
      "Normalized max: 3.000\n",
      "\n",
      "Stats for confidence_metaphysics:\n",
      "Original mean: 0.208\n",
      "Original std: 0.052\n",
      "Normalized mean: -0.000\n",
      "Normalized std: 1.000\n",
      "Normalized min: -2.753\n",
      "Normalized max: 2.779\n",
      "\n",
      "Stats for confidence_science:\n",
      "Original mean: 0.103\n",
      "Original std: 0.082\n",
      "Normalized mean: -0.050\n",
      "Normalized std: 0.784\n",
      "Normalized min: -0.998\n",
      "Normalized max: 3.000\n",
      "\n",
      "Stats for confidence_religion:\n",
      "Original mean: 0.105\n",
      "Original std: 0.110\n",
      "Normalized mean: -0.054\n",
      "Normalized std: 0.715\n",
      "Normalized min: -0.753\n",
      "Normalized max: 3.000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "confidence_cols = [col for col in df_test.columns if col.startswith('confidence_')]\n",
    "normalized_df = df_test.copy()\n",
    "\n",
    "Z_SCORE_CAP = 3\n",
    "\n",
    "for col in confidence_cols:\n",
    "    topic_mean = normalized_df[col].mean()\n",
    "    topic_std = normalized_df[col].std()\n",
    "    \n",
    "    normalized_df[col] = (normalized_df[col] - topic_mean) / topic_std\n",
    "    \n",
    "    normalized_df[col] = normalized_df[col].clip(lower=-Z_SCORE_CAP, upper=Z_SCORE_CAP).round(3)\n",
    "\n",
    "for col in confidence_cols:\n",
    "    print(f\"\\nStats for {col}:\")\n",
    "    print(f\"Original mean: {df_test[col].mean():.3f}\")\n",
    "    print(f\"Original std: {df_test[col].std():.3f}\")\n",
    "    print(f\"Normalized mean: {normalized_df[col].mean():.3f}\")\n",
    "    print(f\"Normalized std: {normalized_df[col].std():.3f}\")\n",
    "    print(f\"Normalized min: {normalized_df[col].min():.3f}\")\n",
    "    print(f\"Normalized max: {normalized_df[col].max():.3f}\")\n",
    "\n",
    "normalized_df.to_csv('normalized_120.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Verification:\n",
      "Rows with all zeros: 0 (should be 0)\n",
      "\n",
      "Stats for confidence_politics:\n",
      "Number of 1s: 23 (35.4%)\n",
      "Number of 0s: 42 (64.6%)\n",
      "\n",
      "Stats for confidence_ethics:\n",
      "Number of 1s: 24 (36.9%)\n",
      "Number of 0s: 41 (63.1%)\n",
      "\n",
      "Stats for confidence_epistemology:\n",
      "Number of 1s: 23 (35.4%)\n",
      "Number of 0s: 42 (64.6%)\n",
      "\n",
      "Stats for confidence_logic:\n",
      "Number of 1s: 23 (35.4%)\n",
      "Number of 0s: 42 (64.6%)\n",
      "\n",
      "Stats for confidence_metaphysics:\n",
      "Number of 1s: 23 (35.4%)\n",
      "Number of 0s: 42 (64.6%)\n",
      "\n",
      "Stats for confidence_science:\n",
      "Number of 1s: 23 (35.4%)\n",
      "Number of 0s: 42 (64.6%)\n",
      "\n",
      "Stats for confidence_religion:\n",
      "Number of 1s: 23 (35.4%)\n",
      "Number of 0s: 42 (64.6%)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "confidence_cols = [col for col in df_test.columns if col.startswith('confidence_')]\n",
    "binary_df = df_test.copy()\n",
    "\n",
    "for col in confidence_cols:\n",
    "    threshold = binary_df[col].quantile(0.65)\n",
    "    binary_df[col] = (binary_df[col] >= threshold).astype(int)\n",
    "\n",
    "all_zeros = binary_df[confidence_cols].sum(axis=1) == 0\n",
    "if all_zeros.any():\n",
    "    for idx in binary_df[all_zeros].index:\n",
    "        best_topic = df_test.loc[idx, confidence_cols].idxmax()\n",
    "        binary_df.loc[idx, best_topic] = 1\n",
    "\n",
    "print(\"\\nVerification:\")\n",
    "all_zeros_after = binary_df[confidence_cols].sum(axis=1) == 0\n",
    "print(f\"Rows with all zeros: {all_zeros_after.sum()} (should be 0)\")\n",
    "\n",
    "for col in confidence_cols:\n",
    "    num_ones = binary_df[col].sum()\n",
    "    total = len(binary_df[col])\n",
    "    print(f\"\\nStats for {col}:\")\n",
    "    print(f\"Number of 1s: {num_ones} ({(num_ones/total)*100:.1f}%)\")\n",
    "    print(f\"Number of 0s: {total-num_ones} ({((total-num_ones)/total)*100:.1f}%)\")\n",
    "\n",
    "binary_df.to_csv('test_results_binary3.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_project_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
